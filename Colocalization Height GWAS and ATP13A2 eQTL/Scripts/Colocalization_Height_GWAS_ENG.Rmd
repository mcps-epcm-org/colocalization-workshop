---
title: "Colocalization of Height GWAS Locus and ATP13A2 eQTL"
author: "Misa Graff"
date: "`r format(Sys.time(), '%B %d, %Y, %R')`"
knit: (function(inputFile, encoding) { 
      out_dir <- '../Documents/Colocalization';
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), out_dir)) })
output: 
  html_document:
   toc: true
---

```{=html}
<style type="text/css">
  body{
  font-size: 12pt;
}
</style>
```
```{css format, echo=FALSE}
.code-lock {
  background-color: #E8EAF1;
  border: 3px solid #DFE2EC;
  font-weight: bold;
}
.code-key {
  background-color: #E8EAF1;
  border: 3px solid #DFE2EC;
  font-weight: bold;
}
```

```{r setup, include=FALSE}

knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE, 
                      echo = TRUE,
                      class.source="code-lock",
                      class.output="code-lock") 

```

```{r clear work area}

# Clean R enviroment 
rm(list = ls(all = TRUE))

```

------------------------------------------------------------------------

########################################################## 

# Genetic colocalization

########################################################## 

“Genetic colocalization is a statistical method that identifies genetic factors shared between two or more traits at a specific locus. It can help uncover overlapping causal variants that cause complex or molecular disease phenotypes. For example, if the signal at a given genetic locus for a trait and gene expression level colocalize, this could indicate a gene's role in causing the disease.  Another example, if the signals for protein level and gene expression level colocalize, this could indicate a gene's role in making that protein.  A third example, if the signals at a given locus for two traits (e.g. blood pressure and coronary heart disease) colocalize, this could indicates the role of this genetic locus on both of these traits together (e.g. blood pressure impacting coronary heart disease).

We can use a packages called ‘coloc’ in R to look at the signals at a genetic locus together for two different traits, protein, or expression levels and see if they colocalize.”

------------------------------------------------------------------------

########################################################## 

## 0. R program preparation

########################################################## 

The `coloc` and `Rfast` packages are used for the analyses in this document. The former has functions to perform colocalization tests, load `ggplot2`, `data.table` and other additional packages. `Rfast` has a number of functions for data analysis, such as linear and logistic regressions, and to obtain descriptive statistics.

We can install them with the following commands:

```{r install packages, echo=TRUE}

install.packages("coloc")
install.packages("Rfast")

# For othe functions in this document 
install.packages("kableExtra")   # Expands on kables

```

To load the packages in *R* we can run the following commands:  

```{r libraries, echo=TRUE}

library("coloc")
library("Rfast")

# The pipe
library(tidyverse)

```

------------------------------------------------------------------------

########################################################## 

## 1. Reading and preparting the input

########################################################## 

As we mentioned before, to perform the colocalization analysis we are going to use the `coloc` package. The arguments required for this package are as follows:

-   `file1` GWAS 1 file, here assumed to be eQTLs for a transcript.
-   `file2` GWAS 2 file, summary statistics from a GWAS.
-   `trait1` Trait 1, could be the gene name.
-   `trait1` Trait 2, would be the phenotype of the GWAS.

To run the first example of colocalization we have to assign values to each of the arguments to be used in our functions.

```{r files}

file1 <- "ENSG00000159363.17.GTEx.eqtl.txt"

file2 <-  "Height_HIS.GWAS.ENSG00000159363.coloc.input"

trait1 <- "ENSG00000159363"

trait2 <- "height"

```

To continue with the analysis, we need to set up the **working directory**. This is where we are going to get our data and where we will save the results of the analysis. To find out where our working directory is and to set a new one, we can run the following commands:

With `getwd()` we get the current working directory:

```{r wd}

getwd()

```

**Important:** the result of this command will give the path to the directory or folder where we are working.

Establish a new working directory with `setwd()`. We can indicate the new **path** of the new working directory:

```{r setwd, eval=FALSE}

setwd("~My_new_dir/coloc")

```

The first step is import the table with summary statistics for region from gwas1/eqtls:

```{r read eqtl}

eqtl <- read.table(file1,                    # eQTLs 
                   header = T,               # Header contains variable names
                   stringsAsFactors = F)     # String variables are transform to factor.  

```

Read summary statistics for GWAS2- 

```{r read gwas}
gwas <- read.table(file2,                    # Summary stats
                   header = T,               
                   stringsAsFactors = F)     
```

We assign names to the rows of each of the tables in order to be able to compare them. These names must be unique.

```{r row names}

rownames(eqtl) <- eqtl$rsID
rownames(gwas) <- gwas$MarkerName

```

After importing the data into our work area and preparing it, we can check for significant variables in the GWAS.

```{r signal and significance}

if (dim(gwas[which(gwas$p_value < 1e-5),])[1] > 0){
  cat(" Is there a suggestive signal in GWAS2 (P < 1e-5)?", "\n",
      "Yes, there is a suggestive signal.", "\n\n")
  } else {
  cat(" Is there a suggestive signal in GWAS2 (P < 1e-5)?", "\n",
      "No, there is no suggestive signal.", "\n\n")
    }

if(dim(gwas[which(gwas$p_value < 5e-8),])[1]>0){
  cat(" Is there a significant signal in GWAS2?", "\n", 
      "Yes, there is significant signal.", "\n\n")
  } else {
  cat(" Is there a significant signal in GWAS2?", "\n",
      "No, no significant signal was identified.", "\n\n")
  }

```

Next, we will create a list with the names of each RSID (Reference SNP cluster ID) that are in the GWAS table. Keeping only the variants that have a valid P value.

```{r tables match}

# Match between RSID from GWAS and eQTL.
eqtl <- eqtl[gwas$MarkerName, ]

# Remove NA (Missings) in P-val variable
eqtl <- eqtl[which(!is.na(eqtl$pval_asc)), ]

```

So far, our files should look like this:

```{r data so-far1}

kable(head(eqtl), booktabs = T, caption = "eQTL Table") %>%
  kableExtra::kable_styling(latex_options = c("scale_down", "HOLD_position"),
                            font_size = 11, position = "center") %>% 
  kableExtra::kable_classic(full_width = F) %>%   
  kableExtra::add_footnote("The first six observations are shown", notation = "symbol")

kable(head(gwas), booktabs = T, caption = "GWAS Table") %>% 
  kableExtra::kable_styling(latex_options = c("scale_down", "HOLD_position"), 
                            font_size = 11, position = "center") %>% 
  kableExtra::kable_classic(full_width = F) %>% 
  kableExtra::add_footnote("The first six observations are shown", notation = "symbol")

```

------------------------------------------------------------------------

########################################################## 

## 2. Files needed to run PLINK: Format and QC

########################################################## 

We have to obtain two files. The first one has the output allele name and allele reference. The second file contains only the allele names.

First we have to create a new directory where to save the output. This can be done manually with the file explorer, directly in the terminal with `mkdir`, or with `dir.crate()`. For the last two we need the **path** to the new directory.

```{r LD Dir}

my_directory <- getwd()

dir.create(                      # Creates new directory (folder)
  paste0(my_directory,           # paste0() joins two strings, no spaces
         "/LD"))                 # New directory name

```

To create a new directory from the terminal we can run `mkdir` from R:

```{r mkdir, echo=TRUE, eval=FALSE}

system('mkdir LD')       # `system()` Runs the argument in terminal 

```

Or we can do it directly form the termial:

```{r mkdir bash, eval=FALSE, engine='bash'}

mkdir LD

```

We proceed to generate tables with allele information.

```{r salvar tables}

write.table(
  # Select 'rsID' y 'REF' form eQTL data set
  x = eqtl[, c('rsID', 'REF')], 
  
  # OPuput path and file name  
  file = paste0(my_directory, '/LD/', trait1, '.SNP.REF.txt'),
  
  # Other options 
  col.names = F, row.names = F, sep = '\t', quote = F)   

write.table(
  # Select 'rsID' from GWAS data set
  x = eqtl[, c('rsID')], 
  
  # OPuput path and file name  
  file =  paste0(my_directory, '/LD/', trait1, '.SNP.REF.txt'), 
  
  # Other options
  col.names=F, row.names=F, sep='\t', quote=F) 

```

With the resulting files, we will run `plink` to obtain *Linkage Disequilibrium* (LD), from **1KG.AMR** and **1KG.EUR**.

```{r plink bim}

# Depending on your system, you have to call plink directly. 
plink2 <- paste0("/apps/plink/", "plink")      # Example of plink location path

plink <- "plink"

CHR <- "chr1"

system(
  paste0(plink, 
         # input Variant Call Format file (".vcf" )
         ' --vcf 1KG.AMR.GRCH38.rsID.', CHR, '.region.vcf.gz',
         
         # List of variants ID's
         ' --extract LD/', trait1, '.SNP.extract',
         
         # System option, CPU threads to be used. 
         ' --threads 1', 
         
         # Update reference aleles 
         ' --update-ref-allele LD/', trait1, '.SNP.REF.txt 2 1',
         
         # Calculates and reports crude correlations
         ' --r square',
         
         # Outpu path and file names
         ' --out Data/LD/AMR', trait1, '.LD', 
         
         # generate only ".bim" file
         ' --make-just-bim'))

system(
  paste0(plink, 
         ' --vcf 1KG.EUR.GRCH38.rsID.', CHR, '.region.vcf.gz', 
         ' --extract LD/', trait1,'.SNP.extract', 
         ' --threads 1',
         ' --update-ref-allele LD/', trait1,'.SNP.REF.txt 2 1', 
         ' --r square',
         ' --out LD/EUR', trait1,'.LD', 
         ' --make-just-bim'))

```

Afterwards, read the `.bim` **AMR** and **EUR** files generated from `plink`. These files list the variants, their positions and alleles.

```{r read bim}

amrbim <- read.table(paste0('LD/AMR', trait1, '.LD.bim'), header=F)

eurbim <- read.table(paste0('LD/EUR', trait1, '.LD.bim'), header=F)

```

Assign names to each colums of `.bim` files.

```{r, echo=TRUE}

colnames(amrbim) <- c("chr", "rsid", "cM", "position", "allele1", "allele2")
colnames(eurbim) <- c("chr", "rsid", "cM", "position", "allele1", "allele2")

```

### The LD for AMR has a few more variants. 

When we compare the number of variants included in the **AMR** and **EUR** tables, the former has `r nrow(amrbim) - nrow(eurbim)` variants more.

```{r}

nrow(amrbim)

nrow(eurbim)

```

Read the LD matrix to explore **missing** (**NA**) values. All values are numeric. 

```{r}

ldamr <-  as.matrix(read.table(paste0('LD/AMR', trait1, '.LD.ld'), header=F, stringsAsFactors=F))

ldeur <-  as.matrix(read.table(paste0('LD/EUR', trait1, '.LD.ld'), header=F, stringsAsFactors=F))

```

After loading all data sets, assign names to all columns and rows in the matrix. Use rsIDs for each group (AMR, EUR).

```{r}
# AMR
colnames(ldamr) <- amrbim[, "rsid"] # Col 
rownames(ldamr) <- amrbim[, "rsid"] # Row

# eur
colnames(ldeur) <- eurbim[, "rsid"] # Col
rownames(ldeur) <- eurbim[, "rsid"] # Row
```

Check if within the matrices there is data with **missings** (**NA**). This is necessary because for our analysis the LD matrices cannot have missing values and have to be of the same size.

```{r}
# Sum all values with missing on each column

miss.amr <- colSums(is.na(ldamr)) 
miss.eur <- colSums(is.na(ldeur)) 

max(miss.eur)
min(miss.eur)

max(miss.amr)
min(miss.amr)

```

Only the AMR LD matrix has missing values. Let's identify which SNP has NA's.  

```{r}

colnames(ldamr)[colSums(is.na(ldamr)) > 0]

```

```{r, eval=FALSE}

colnames(ldeur)[colSums(is.na(ldeur)) > 0]
#  output too long

```

```{r, echo=FALSE}
# Print the first 50 rows, with output message 
cat(head(colnames(ldeur)[colSums(is.na(ldeur)) > 0], n = 50), "...",
    paste0("\n\nOther ", length(colnames(ldeur)[colSums(is.na(ldeur)) > 0]) - 50, " variants reported"))
```

```{r}

colnames(ldeur)[colSums(is.na(ldeur)) > 10]

```

After analyzing the data, we determined that the culprit SNP is `r colnames(ldeur)[colSums(is.na(ldeur)) > 10]`. Remove it from `eurbim` file.

```{r}

eurbim <- eurbim[eurbim$rsid != "rs78116095",]

nrow(eurbim)

```

After removing the SNP from the data set, we are left with `r nrow(eurbim)` variants in EUR data set. Let us recall that the AMR database has more variants than the EUR database (`r nrow(amrbim)` vs `r nrow(eurbim)`), so we have to rework AMR database so that both have the same variants.

```{r}

write.table(eurbim[,c(2,5)],                          # rsID y REF colums
            paste0('LD/',trait1,'.SNP.REF.txt'), 
            col.names=F, row.names=F, sep='\t', quote=F)

write.table(eurbim[,2],                               # rsID column 
            paste0('LD/', trait1, '.SNP.extract'), 
            col.names=F, row.names=F, sep='\t', quote=F)

```

### Write a table with just variants names

With our data sets ready, re-run `plink` to get LD, here from 1KG.AMR and EUR, using the updated files.  

```{r plink bim2}

system(
  paste0(plink,
         ' --vcf 1KG.AMR.GRCH38.rsID.', CHR, '.region.vcf.gz',
         ' --extract LD/', trait1, '.SNP.extract',
         ' --threads 1', 
         ' --update-ref-allele LD/', trait1, '.SNP.REF.txt 2 1',
         ' --r square',
         ' --out LD/AMR', trait1, '.LD', 
         ' --make-just-bim'))

system(
  paste0(plink, 
         ' --vcf 1KG.EUR.GRCH38.rsID.', CHR, '.region.vcf.gz', 
         ' --extract LD/', trait1,'.SNP.extract', 
         ' --threads 1',
         ' --update-ref-allele LD/', trait1,'.SNP.REF.txt 2 1', 
         ' --r square',
         ' --out LD/EUR', trait1,'.LD', 
         ' --make-just-bim'))

```

Read `.bim` files created by `plink`.

```{r}

amrbim <- read.table(paste0('LD/AMR',trait1,'.LD.bim'), header=F)

eurbim <- read.table(paste0('LD/EUR',trait1,'.LD.bim'), header=F)

```

Assign names to all colums. 

```{r}

colnames(amrbim) <- c("chr", "rsid", "cM", "position", "allele1", "allele2")

colnames(eurbim) <- c("chr", "rsid", "cM", "position", "allele1", "allele2")

```

Check if **AMR** y **EUR** have the same number variant.  

```{r}

nrow(eurbim)

nrow(amrbim)

```

Create a list of markers names (rsIDs) that are in **AMR** y **EUR** `.bim` files. 

```{r}
eqtl <- eqtl[eurbim$rsid, ]

gwas <- gwas[amrbim$rsid, ]
```

Next, we check that all files so far are equal in size of rows and columns.

```{r}
dim(gwas)
dim(eqtl)
```

```{r}
dim(amrbim)
dim(eurbim)
```

Read LD matrices (numeric values). 

```{r}
ldamr <- as.matrix(read.table(paste0('LD/AMR',trait1,'.LD.ld'), header=F, stringsAsFactors=F))

ldeur <- as.matrix(read.table(paste0('LD/EUR',trait1,'.LD.ld'), header=F, stringsAsFactors=F))
```

Assign rsIDs to each column and row.  

```{r}
colnames(ldamr) <- amrbim[, "rsid"]
rownames(ldamr) <- amrbim[, "rsid"]
colnames(ldeur) <- eurbim[, "rsid"]
rownames(ldeur) <- eurbim[, "rsid"]
```

Re-check values with **missings** (**NA**).

```{r}
colnames(ldamr)[colSums(is.na(ldamr)) > 0]

colnames(ldeur)[colSums(is.na(ldeur)) > 0]
```

**Neither of the matrices contains missing values.**

------------------------------------------------------------------------

######################################################################## 

## 3. Create the necessary datasets that focus on comparing P-values 

######################################################################## 


We need to generate two lists:

1.  List with the required elements for trait 1 (`trait1`) and file 1 (**eQTL**).
2.  List with the required elements for trait 2 (`trait2`) and file 2 (**GWAS**).

Each list must contain the following elements:

- **pvalues**, are the p-values of each SNP.
- **snp**, name of the marker in the two databases.
- **MAF**, frequency of the effect allele.
- **position**, position of the marker.
- **type**, we specify `'quant'` for continuous traits (_cc_ indicates case-control).
- **N**, sample size.
- **s** fraction of the sample that are cases, (Only necessary if cc is indicated; as we are using a quantitative trait we do not include it).

```{r}
eqtl.d <- 
  list(pvalues = eqtl[eurbim$rsid, 'pval_asc'],
       snp = eqtl[eurbim$rsid, 'rsID'],
       MAF = eqtl[eurbim$rsid, 'maf_trc'], 
       position = eurbim$position, 
       type = 'quant',
       N = eqtl$samples_asc[1])

gwas.d <- 
  list(pvalues = gwas[amrbim$rsid,'p_value'],
       snp = gwas[ amrbim$rsid, 'MarkerName'], 
       MAF = gwas[amrbim$rsid, 'EAF'], 
       position = amrbim$position, 
       type = 'quant',
       N = 50000)
```

Check the data is OK. For this we use `check_dataset()` function which is part of the `coloc` package; if our data is OK the output will be `NULL`.

```{r}
check_dataset(eqtl.d, req = c("snp", "pvalues"))
check_dataset(gwas.d, req = c("snp", "pvalues"))
```

**Our information is correct. We proceed with our analysis.**

------------------------------------------------------------------------

############################################################################## 

## 4. Create the databases that focus on comparing betas 𝛽 (_VarBeta_)

############################################################################## 

For the input we need the variance. Calculate this with the standard error ($se$) of the beta ($beta$).

```{r}
eqtl$varbeta <- eqtl$beta_se_asc ^ 2

gwas$varbeta <- gwas$se_0 ^ 2
```

Afterwards, obtain a list with all the elements required for trait 1 (`trait1`) and 2 (`trait2`), corresponding to each file (**eQTL**, **GWAS**). 

Each list must contain the following elements:

- **snp**, marker name in the two databases.
- **beta**, value of beta $beta**.
- **varbeta**, variance of beta $beta$. $(sebeta)^2$.
- **position**, marker position.
- **type**, we specify `'quant'` for continuous traits (_cc_ indicates case-control).
- **N**, sample size.
- **LD**, DL matrix (**not included**).
- **sdY**, Standard deviation of $Y$.
- **MAF**, frequency of the effect allele.

```{r}
eqtl.d2 <- 
  list(snp = eqtl[eurbim$rsid, 'rsID'], 
       beta = eqtl[eurbim$rsid, 'beta_asc'],
       varbeta = eqtl[eurbim$rsid, 'varbeta'], 
       position = eurbim$position, 
       type = 'quant', 
       N = eqtl$samples_asc[1],
       LD = ldeur, 
       sdY = 1, 
       MAF = eqtl[eurbim$rsid, 'maf_trc'])

gwas.d2 <- 
  list(snp = gwas[amrbim$rsid, 'MarkerName'], 
       beta = gwas[amrbim$rsid, 'beta_0'], 
       varbeta = gwas[amrbim$rsid, 'varbeta'], 
       position = amrbim$position, 
       type = 'quant', 
       N = 50000, 
       LD = ldamr, 
       sdY=1, 
       MAF = gwas[amrbim$rsid, 'EAF'])
```

Verify that the databases are OK; emphasizing on the **LD**. Use `check_dataset()` again from `coloc` package; if our data is OK the output we will get is `NULL`.

```{r}
check_dataset(eqtl.d2,req = c("snp", "varbeta", "beta", "MAF"))
check_dataset(gwas.d2,req = c("snp", "varbeta", "beta", "MAF"))
```

**Our information is correct. We proceed with our analysis.**

------------------------------------------------------------------------

############################ 

## 5. Running coloc

############################ 

### P-values {.tabset}

Run the first colocalization analyses using P-values. `coloc.abf()` function performs the analysis using the first two lists generated in the **third topic** (**gwas.d** and **eqtl.d**). This function calculates the posterior probabilities of different causal variants configurations under the assumption of a single causal variant for each trait.

```{r}
my.res <- coloc.abf(dataset1 = gwas.d, dataset2 = eqtl.d)
```

Although the results are saved in an object (`my.res`), we get an output in the console. 

#### Analysis results

Results of colocalization analysis of traits 1 and 2 by P-value method.

```{r}

print(my.res)

```

#### Plot

```{r, fig.align='center'}

plot(my.res)

```

## {-}

------------------------------------------------------------------------

### Betas $\beta$ {.tabset}

Continue with the colocalization analyses by changing the method of analysis by means of the $beta betas. We use the two lists we generated in **topic 4** (**gwas.d2** and **eqtl.d2**). 

```{r}

my.res.bvar <- coloc.abf(dataset1 = gwas.d2, dataset2 = eqtl.d2)

```

#### Analysis results
Results of colocalization analysis of traits 1 and 2 by Betas method.

```{r}
print(my.res.bvar)
```

#### Plot

```{r, fig.align='center'}
plot(my.res.bvar)
```

## {-}

Examine whether the posterior probability of H4 is at least **0.5** in the two methods. 

```{r}
print(subset(my.res$results, SNP.PP.H4 > 0.1))

print(subset(my.res.bvar$results, SNP.PP.H4>0.1))
```

```{r}
# Other print 

my.res$results %>% 
  filter(SNP.PP.H4 > 0.1) %>% 
  kable(booktabs = T) %>%
  kableExtra::kable_styling(latex_options = c("scale_down", "HOLD_position"),
                            font_size = 11, position = "center") %>% 
  kableExtra::kable_classic(full_width = F)   

my.res.bvar$results %>% 
  filter(SNP.PP.H4 > 0.1) %>% 
  kable(booktabs = T) %>%
  kableExtra::kable_styling(latex_options = c("scale_down", "HOLD_position"),
                            font_size = 11, position = "left") %>% 
  kableExtra::kable_classic(full_width = F)   

```

------------------------------------------------------------------------

################################################################ 

## 6. SuSiE for multiple causal variables, alternative analysis

################################################################

This analysis uses the datasets made with the betas variance method that includes LD. In this analysis we use the following elements: 

- **snp**, marker name in the two databases.
- **beta**, value of beta $beta.
- **varbeta**, variance of beta $beta$. $(sebeta)^2$$.
- **position**, marker position.
- **type**, we specify `'quant'` for continuous traits (_cc_ indicates case-control).
- **N**, sample size.
- **LD**, DL matrix (**to be used**).
- **sdY**, Standard deviation of $Y$.
- **MAF**, frequency of the effect allele.
- **cc**, indicates cases and controls.

Run SuSiE on each dataset.

```{r}
eqtl.s <- runsusie(eqtl.d2)

gwas.s <- runsusie(gwas.d2)
```

Plot each dataset highlighting each credible SNP groups.  

```{r, echo=TRUE, figures-side, fig.show="hold", out.width="50%"}
plot_dataset(gwas.d2, susie_obj = gwas.s, color = c("green4"))
plot_dataset(eqtl.d2, susie_obj = eqtl.s, color = c("yellow4"))
```

Run `coloc.susie()` to colocalize evaery pair of signals.  

```{r}
susie.res <- coloc.susie(gwas.s, eqtl.s)

susie.res$summary %>%
  kable(booktabs = T) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position",
                            font_size = 15, position = "center") %>% 
  kableExtra::kable_paper(full_width = F)   
```

```{r}
susie.res$results %>% 
  filter(SNP.PP.H4.abf > 0.05) %>% 
  kable(booktabs = T) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position",
                            font_size = 15, position = "center") %>% 
  kableExtra::kable_paper("hover", full_width = F)   

```

Perform sensitivity analyses with which we will plot the signals we want to consider. For that, we will plot **Manhattan plots** and **probabilities** for each signal.

```{r, fig.align='center'}
sensitivity(susie.res, "H4 > 0.9", row=1, dataset1 = eqtl.d2, dataset2 = gwas.d2)
```

------------------------------------------------------------------------

####################################### 

## 7. Save results and plots

####################################### 

Based on _P-values_ method: 

-   Save the results if **H4** has the highest posterior probability. 
-   Save the results if the values of SNP.PP.H4 \>0.01. 
-   Save the `coloc.abf` plot.

```{r}

# Run a conditional IF-ELSE algorithm

# Queremos probar si PP.H4.abf es igual al valor máximo de los resultados -1.
if(my.res$summary['PP.H4.abf'] == max(my.res$summary[-1])) { 
  
  # En caso de que se cumpla el criterio, guardamos los resultados. 
	write.table(my.res$summary,
	            paste0(trait1, '.', trait2, '.coloc_abf_gene.pval.txt'),
	            col.names=T, row.names=F, sep='\t', quote=F)
  
  # Guardamos todos los valores cuyo SNP.PP.H4 sea mayor a 0.01.  
	write.table(subset(my.res$results,SNP.PP.H4>0.01),
	            paste0(trait1, '.', trait2, '.coloc_abf_snp.pval.txt'), 
	            col.names=T, row.names=F, sep='\t', quote=F)
	}

# Generamos un archivo `.png` donde se guarde el grpafico. 
png("Height.eqtl.coloc_pvalues.png")
plot(my.res)
dev.off()

```


Based on _Betas_ $\beta$ method: 

-   Save the results if **H4** has the highest posterior probability. 
-   Save the results if the values of SNP.PP.H4 \>0.01. 
-   Save the `coloc.abf` plot.

```{r}

if(my.res.bvar$summary['PP.H4.abf'] == max(my.res.bvar$summary[-1])) {
    write.table(
      my.res.bvar$summary, 
      paste0(trait1, '.', trait2, '.coloc_abf_gene.betas.txt'), 
      col.names=T, row.names=F, sep='\t', quote=F)
  
    write.table(
      subset(my.res.bvar$results, SNP.PP.H4 > 0.01),
      paste0(trait1, '.', trait2, '.coloc_abf_snp.betas.txt'), 
      col.names=T, row.names=F, sep='\t', quote=F)
    }

png("Height.eqtl.coloc_betas.png")
plot(my.res.bvar)
dev.off()

```

Based on _SuSiE_ method:

-   Save the results if **H4** has the highest posterior probability, `coloc-susie` (\>1 causal variant).
-   Save the results if the values of SNP.PP.H4 \>0.01, `coloc-susie` (\>1 causal variant).
-   Save the plots of each data set that include the `runsusie` results.
-   Save the Manhattan-plots and probabilities for each signal.

```{r}

write.table(susie.res$summary, 
            paste0(trait1, '.', trait2, '.coloc_susie_abf_gene.txt'),
            col.names=T, row.names=F, sep='\t', quote=F)

write.table(subset(susie.res$results, SNP.PP.H4.abf > 0.01),
            paste0(trait1, '.', trait2, '.coloc_susie_abf_snp.txt'),
            col.names=T, row.names=F, sep='\t', quote=F)

png("Height.gwas.susie_obj.png")
plot_dataset(gwas.d2,susie_obj=gwas.s,color = c("green4"))
dev.off()

png("Height.eqtl.susie_obj.png")
plot_dataset(eqtl.d2,susie_obj=eqtl.s,color = c("yellow4"))
dev.off()

png("Height.gwas.eqtl.susie_probs.png")
sensitivity(susie.res,"H4 > 0.9", 
            row=1, 
            dataset1 = eqtl.d2, 
            dataset2 = gwas.d2)
dev.off()


```

